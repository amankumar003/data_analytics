# OLYMPICS AZURE END TO END DATA ENGINEERING | Azure Cloud | Python | SQL | DataBricks | Synapse Analytics 
•Developed an Azure-based end-to-end data analytics pipeline for a
comprehensive Olympic dataset, over 11,000 athletes and 743 teams,
and streamlined data ingestion with ADF.<br>
• Leveraged ADLS for large-scale data handling and Azure Databricks for
data transformation, complemented by Azure Synapse Analytics for
optimized data warehousing.<br>
• Providing deep insights with the creation of dynamic visualizations and
reports using Power BI.

![image](https://github.com/amankumar003/olympics_azure_end_to_end_data_engineering/assets/91831652/3beec0c6-9fb0-435e-85ff-2d620f4bf67e)

## Architecture

![Architecture](images/arch.png)

The architecture of the project consists of the following components:

- **Azure Databricks**: Used for data processing, transformation, and analysis. It provides a collaborative and interactive environment for running Spark-based jobs.

- **Azure Data Factory**: Manages and orchestrates the data workflow. It is responsible for data ingestion from various sources, data transformation, and scheduling of jobs.

- **Azure Storage**: Serves as the data lake for storing raw and processed data. It can also host intermediate results generated during the analysis.

- **Azure SQL Database**: Stores the cleaned and transformed data, making it accessible for visualization and reporting.

- **Power BI**: Connects to the Azure SQL Database to create interactive and visually appealing dashboards for data exploration.

## Technologies Used

- Azure Databricks
- Azure Data Factory
- Azure Storage
- Azure SQL Database
- Azure Synapse Analytics

##DataFactory pipeline creation ss

![df_aman_azure](https://github.com/amankumar003/olympics_azure_end_to_end_data_engineering/assets/91831652/7e2c75c2-8206-4a92-94bc-7adfc32c09cf)


